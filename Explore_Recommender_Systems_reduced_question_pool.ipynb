{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\Users\\songyifn\\Desktop\\Recommender-System-for-MathOverflow')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import load_mathoverflow_data as lmd #The method for loading the mathoverflow data is stord in the Python script load_mathoverflow_data.py\n",
    "#load the MathOverflow data set and perform training/testing splitting\n",
    "data = lmd.load_mathoverflow_data(test_set_fraction=0.1, #training/testing split: 90% training, 10% testing\n",
    "                                  indicator_features=False,\n",
    "                                  tag_features=True)\n",
    "\n",
    "train = data['train']\n",
    "test = data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find the indices of the questions which should be kept in the reduced question pool:\n",
    "#the criterion is that the question must be answered at least once\n",
    "to_include=np.where(np.squeeze(train.getnnz(axis=0))>0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use the array of question indices (question ids) to be kept to get the subset of training and testing set through slicing\n",
    "train_new = train.tocsc()[:,to_include].tocoo()\n",
    "test_new = test.tocsc()[:,to_include].tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reduced question pool for the case study has 4513 users and 49773 questions, with 653 interactions in the testing and 96667 interactions in the training set.\n"
     ]
    }
   ],
   "source": [
    "print('The reduced question pool for the case study has %s users and %s questions, '\n",
    "      'with %s interactions in the testing and %s interactions in the training set.'\n",
    "      % (train_new.shape[0], train_new.shape[1], test_new.getnnz(), train_new.getnnz()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Model 1: Baseline Model (non-personalized Popularity-based recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49773"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### order the question id according to their popularity (the counts of times each question has been answered) in descending order\n",
    "order_by_popularity=np.argsort(np.squeeze(train_new.getnnz(axis=0)))[::-1]\n",
    "len(order_by_popularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\songyifn\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\ranking.py:542: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "train_new_csr=train_new.tocsr()\n",
    "test_new_csr=test_new.tocsr()\n",
    "\n",
    "all_auc=[]\n",
    "for i in range(train.shape[0]):\n",
    "    #for each user, first find all question ids that the user did not answer during the time period of the training set,\n",
    "    #then when evaluating the model performance on the testing set, the model will only rank those questions (avoid re-recommending)\n",
    "    indices_kept=np.where(train_new_csr[i,:].toarray()[0]==0)[0]\n",
    "    #the ROC curve is created by comparing the predicted ranking (based on popularity and is the same for every user) and\n",
    "    #the the list of indicators which show whether the user actually answered the question or not at different thresholds\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(pd.Series(test_new_csr[i,:].toarray()[0][indices_kept].astype(int)).apply(lambda x: 1 if x!=0 else 0),\n",
    "                                             order_by_popularity[indices_kept])\n",
    "    auc=metrics.auc(fpr,tpr)\n",
    "    #if a user has not answered any questions during the time period of the testing set, he/she should not be included in the evaluation\n",
    "    if pd.isnull(auc)==False:\n",
    "        all_auc.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popularity-based model testing set AUC: 0.467945\n"
     ]
    }
   ],
   "source": [
    "#calculate the mean AUC score of all users\n",
    "test_auc=round(sum(all_auc)/len(all_auc),6)\n",
    "print('Popularity-based model testing set AUC: %s' % test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Model 2: Pure collaborative filtering model, without any item/user features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lightfm import LightFM # Import the model\n",
    "from lightfm.evaluation import auc_score # Import the evaluation routines\n",
    "\n",
    "# Set the common parameters for the recommender system models used in the case study\n",
    "NUM_THREADS = 2 #Number of parallel threads used in the computation\n",
    "NUM_COMPONENTS = 30 #dimension of the latent factor vectors for users/questions\n",
    "NUM_EPOCHS = 3 #number of training epochs\n",
    "ITEM_ALPHA = 1e-6 #regularization strength parameter for the item features\n",
    "\n",
    "# Fit the collaborative filtering model with WARP loss function\n",
    "model2 = LightFM(loss='warp',\n",
    "                 item_alpha=ITEM_ALPHA,\n",
    "                 no_components=NUM_COMPONENTS)\n",
    "\n",
    "model2 = model2.fit(train_new, epochs=NUM_EPOCHS, num_threads=NUM_THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure collaborative filtering model training set AUC: 0.817615\n"
     ]
    }
   ],
   "source": [
    "# Compute and print the AUC score of the training data\n",
    "train_auc = auc_score(model2, train_new, num_threads=NUM_THREADS).mean()\n",
    "print('Pure collaborative filtering model training set AUC: %s' % train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure collaborative filtering model testing set AUC: 0.676976\n",
      "Pure collaborative filtering testing set AUC (with biases corrected): 0.642542\n"
     ]
    }
   ],
   "source": [
    "# Pass in the interactions in the training set to exclude them from being re-recommended to users.\n",
    "test_auc = auc_score(model2, test_new, train_interactions=train_new, num_threads=NUM_THREADS).mean()\n",
    "print('Pure collaborative filtering model testing set AUC: %s' % test_auc)\n",
    "\n",
    "# Set biases to zero and test the model again\n",
    "model2.item_biases *= 0.0\n",
    "test_auc = auc_score(model2, test_new, train_interactions=train_new, num_threads=NUM_THREADS).mean()\n",
    "print('Pure collaborative filtering testing set AUC (with biases corrected): %s' % test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Model 3: Hybrid model which only uses the tags information as item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<49773x1380 sparse matrix of type '<type 'numpy.float32'>'\n",
       "\twith 125037 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract the subset of the item feature matrix by only including the questions ids that belongs to the reduced question pool\n",
    "item_features_1 = data['item_features']\n",
    "item_features_new_1 = item_features_1[to_include,:]\n",
    "item_features_new_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid model 3 training set AUC: 0.964593\n",
      "Hybrid model 3 testing set AUC: 0.871383\n"
     ]
    }
   ],
   "source": [
    "model3 = LightFM(loss='warp',\n",
    "                 item_alpha=ITEM_ALPHA,\n",
    "                 no_components=NUM_COMPONENTS,\n",
    "                 max_sampled=30)\n",
    "\n",
    "model3 = model3.fit(train_new,\n",
    "                    item_features=item_features_new_1,\n",
    "                    epochs=15,\n",
    "                    num_threads=NUM_THREADS)\n",
    "\n",
    "train_auc = auc_score(model3,\n",
    "                      train_new,\n",
    "                      item_features=item_features_new_1,\n",
    "                      num_threads=NUM_THREADS).mean()\n",
    "print('Hybrid model 3 training set AUC: %s' % train_auc)\n",
    "\n",
    "test_auc = auc_score(model3,\n",
    "                     test_new,\n",
    "                     train_interactions=train_new,\n",
    "                     item_features=item_features_new_1,\n",
    "                     num_threads=NUM_THREADS).mean()\n",
    "print('Hybrid model 3 testing set AUC: %s' % test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Model 4: Hybrid model which include the 50 additional item features from topic modeling of question texts (tags + topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "#create the new item feature matrices for tags+topics and for topics only based on the reduced question pool\n",
    "#load the document-topics matrix obtained from exploring the recommender system using the full question pool \n",
    "item_features_topics=sp.coo_matrix(pd.read_csv('question_topics.csv',header=None),dtype=np.float32).tocsr() \n",
    "item_features_enhanced=sp.hstack([item_features_1,item_features_topics]).tocsr() #concatenate the tags feature and topics feature matrices horizontally\n",
    "item_features_new_enhanced=item_features_enhanced[to_include,:]\n",
    "item_features_new_topics=item_features_topics[to_include,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<49773x1430 sparse matrix of type '<type 'numpy.float32'>'\n",
       "\twith 632721 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features_new_enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<49773x50 sparse matrix of type '<type 'numpy.float32'>'\n",
       "\twith 507684 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features_new_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid model 4 training set AUC: 0.968554\n",
      "Hybrid model 4 testing set AUC: 0.894619\n"
     ]
    }
   ],
   "source": [
    "model4 = LightFM(loss='warp',\n",
    "                 item_alpha=ITEM_ALPHA,\n",
    "                 no_components=NUM_COMPONENTS,\n",
    "                 max_sampled=30)\n",
    "\n",
    "# Fit the hybrid model. The \"enhanced\" item features matrix is passed as an additional argument\n",
    "model4 = model4.fit(train_new,\n",
    "                    item_features=item_features_new_enhanced,\n",
    "                    epochs=15,\n",
    "                    num_threads=NUM_THREADS)\n",
    "\n",
    "train_auc = auc_score(model4,\n",
    "                      train_new,\n",
    "                      item_features=item_features_new_enhanced,\n",
    "                      num_threads=NUM_THREADS).mean()\n",
    "print('Hybrid model 4 training set AUC: %s' % train_auc)\n",
    "\n",
    "test_auc = auc_score(model4,\n",
    "                     test_new,\n",
    "                     train_interactions=train_new,\n",
    "                     item_features=item_features_new_enhanced,\n",
    "                     num_threads=NUM_THREADS).mean()\n",
    "print('Hybrid model 4 testing set AUC: %s' % test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Model 5: Hybrid model which only uses the 50 topical features of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid model 5 training set AUC: 0.918341\n",
      "Hybrid model 5 testing set AUC: 0.8182\n"
     ]
    }
   ],
   "source": [
    "model5 = LightFM(loss='warp',\n",
    "                 item_alpha=ITEM_ALPHA,\n",
    "                 no_components=NUM_COMPONENTS,\n",
    "                 max_sampled=30)\n",
    "\n",
    "# Fit the hybrid model. The topical item features matrix is passed as an additional argument\n",
    "model5 = model5.fit(train_new,\n",
    "                    item_features=item_features_new_topics,\n",
    "                    epochs=15,\n",
    "                    num_threads=NUM_THREADS)\n",
    "\n",
    "train_auc = auc_score(model5,\n",
    "                      train_new,\n",
    "                      item_features=item_features_new_topics,\n",
    "                      num_threads=NUM_THREADS).mean()\n",
    "print('Hybrid model 5 training set AUC: %s' % train_auc)\n",
    "\n",
    "test_auc = auc_score(model5,\n",
    "                     test_new,\n",
    "                     train_interactions=train_new,\n",
    "                     item_features=item_features_new_topics,\n",
    "                     num_threads=NUM_THREADS).mean()\n",
    "print('Hybrid model 5 testing set AUC: %s' % test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
